<!DOCTYPE html>
<html lang="en">


<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="PATSP-Net">

    <title>PATSP-Net</title>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/charts.css/dist/charts.min.css">
    <link id="theme-style" rel="stylesheet" href="./Packages/ICCTUNet/css/avatarclip_main.css">
    <link id="theme-style" rel="stylesheet" href="./Packages/ICCTUNet/css/bulma-carousel.min.css">
    <link id="theme-style" rel="stylesheet" href="./Packages/ICCTUNet/css/bulma-slider.min.css">

    <!-- <script type="module" src="./assets/js/background_box.js"></script> -->
    <script type="module" src="./js/background_star.js"></script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="./Packages/ICCTUNet/js/bulma-carousel.min.js"></script>
    <script src="./Packages/ICCTUNet/js/bulma-slider.min.js"></script>
    <script src="./Packages/ICCTUNet/js/index.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
</head>

<body>
    
    
    <div class="wrapper">
        <section class="section intro-section">
            <div class="intro-container" style="text-align: center;">
                <div class="header">
                    <h3 class="papername">Perception-Aware Texture Similarity Prediction
                    </h3>
                </div>
                <ul class="list-unstyled name-list">
                    <li><a href="" target="_blank">Weibo Wang</a></li>
                    <li><a href="https://scholar.google.com/citations?user=InD0J_IAAAAJ&hl=en&oi=ao" target="_blank">Xinghui Dong</a></li>
    
                </ul>
                <ul class="list-unstyled name-list">
                    <li><a href="https://indtlab.github.io/" target="_blank">INDTLab, Ocean University of China </a></li>
                </ul>
            </div>
            </br>
       

        <div align="center">
        <div class="container">
            <div class="columns is-multiline is-centered">
              <table>
                <tr>
                  <td style="padding:5px 5px 5px 5px;">
                      <img src='./Packages/PATSP-Net/archi.PNG' height="644" width="1178" />
                  </td>
              </table>
            </div>
          </div>
            <p> The architecture of the proposed PATSP-Net, which contains the BiLAViT (a) and the RSLoss (e). Also, the internal structures of CI-BFM, BiLA
            and BAB are shown in (b), (c) and (d) respectively.
            </p>            
            
        </div>
    </section>

        <section class='section'>
            <div class="section-title">
                Abstract
            </div>
            <div class="details" style="text-align: justify" ;>
                Texture similarity plays important roles in texture analysis and material recognition. However, perceptuallyconsistent fine-grained texture similarity prediction is still challenging. The discrepancy between the texture similarity data
                obtained using algorithms and human visual perception has been demonstrated. This dilemma is normally attributed to the texture representation and similarity metric utilised by the algorithms,
                which are inconsistent with human perception. To address this
                challenge, we introduce a Perception-Aware Texture Similarity
                Prediction Network (PATSP-Net). This network comprises a
                Bilinear Lateral Attention Transformer network (BiLAViT) and
                a novel loss function, namely, RSLoss. The BiLAViT contains
                a Siamese Feature Extraction Subnetwork (SFEN) and a Metric
                Learning Subnetwork (MLN), designed on top of the mechanisms
                of human perception. On the other hand, the RSLoss measures
                both the ranking and the scaling differences. To our knowledge,
                either the BiLAViT or the RSLoss has not been explored for
                texture similarity tasks. The PATSP-Net performs better than,
                or at least comparably to, its counterparts on three data sets
                for different fine-grained texture similarity prediction tasks. We
                believe that this promising result should be due to the joint
                utilization of the BiLAViT and RSLoss, which is able to learn the
                perception-aware texture representation and similarity metric.
                
            </div>
        </section>
        
        
        <section class='section links-section'>
            <div class='section-title'>
                Links
            </div>
            <div class='details links-table'>
                <table>
                    <tr>
                        <td>
                            <div class='links-container'>
                                <a href='https://github.com/INDTLab/ICCTUNet/blob/main/Small%20Sample%20Image%20Segmentation%20By%20Coupling%20Convolutions%20and%20Transformers.pdf' target="_blank"><img class='links-cover'src='./Packages/CCMSRNet/Data/Cover.png' alt='PDF Cover' width="140"></a>
                            </div>
                        </td>
                        <td>
                            <div class='links-container'>
                                <a href='https://github.com/INDTLab/PATSP-Net' target="_blank"><img class='links-cover'
                                        src='./Packages/CCMSRNet/Data/github.png' alt='github icon' width="160"></a>
                            </div>
                        </td>
                    </tr>
                    
                    <tr>
                        <td>
                            <a href='https://github.com/INDTLab/ICCTUNet/blob/main/Small%20Sample%20Image%20Segmentation%20By%20Coupling%20Convolutions%20and%20Transformers.pdf' target="_blank">Paper</a>
                            Paper
                        </td>
                        <td><a href='https://github.com/INDTLab/PATSP-Net' target="_blank">Code</a></td>
                        
                    </tr>
                    
                </table>
            </div>
        </section>


        <section class="section">
            <div class="section-title">
                Experimental Results
            </div>
            <div align="center">
                <div class="container">
                    <div class="columns is-multiline is-centered">
                      <table>
                        
                        <tr>
                            <td style="padding:5px 5px 5px 5px;">
                                <img src='./Packages/ICCTUNet/Data/results/TableI.png' height="80%" width="100%" />
                            </td>
                            <td style="padding:5px 5px 5px 5px;">
                                <img src='./Packages/ICCTUNet/Data/results/TableII.png' height="80%" width="100%" />
                            </td>
                            
                        
                          </tr>
                      </table>
                    </div>
                  </div>
                    <p> <b>Quantitative Results on Medical Image Segmentation datasets Synapse, ACDC.</b></p>            
                    
                </div>
            
                <div align="center">
                    <div class="container">
                        <div class="columns is-multiline is-centered">
                          <table>
                            <tr>
                                <td style="padding:5px 5px 5px 5px;">
                                    <img src='./Packages/ICCTUNet/Data/results/all_visualize.png' height="80%" width="100%" />
                                </td>
                              </tr>
                              <tr> <td> <hr></td> </tr>
                                
                                    
                                
                                
                                
                              
                              <!-- <tr>
                                <td style="padding:5px 5px 5px 5px;">
                                    <img src='./Packages/CCMSRNet/Data/results/SUIM_half.png' height="80%" width="100%" />
                                </td>
                              </tr>
                              <tr> <td> <hr></td> </tr>
                              <tr>
                                <td style="padding:5px 5px 5px 5px;">
                                    <img src='./Packages/CCMSRNet/Data/results/EUVP_half.png' height="80%" width="100%" />
                                </td>
                              </tr>
                              <tr> <td> <hr></td> </tr>
                            <tr>
                              <td style="padding:5px 5px 5px 5px;">
                                  <img src='./Packages/CCMSRNet/Data/results/C60_half.png' height="80%" width="100%" />
                              </td>
                            </tr>
                            <tr> <td> <hr></td> </tr>

                            <tr>
                                <td style="padding:5px 5px 5px 5px;">
                                    <img src='./Packages/CCMSRNet/Data/results/RUIE_half.png' height="80%" width="100%" />
                                </td>
                              </tr> -->
                            
            
                             
                            
                              
                          </table>
                        </div>
                      </div>
                        <p> <b> Qualitative Results on Medical Image Segmentation and Defect Image Segmentation of (a) UNet, (b) TransUnet, (c) SwinUnet and ours (d) ICCTUNet-T, (e) ICCTUNet-C, (f) ICCTUNet-F and (g) Ground-Truth</b> </p>            
                        
                    </div>
        </section>
        

        <section>
    
<!--             <p>We referred to the project page of <a href="https://ykdai.github.io/projects/BracketFlare">BracketFlare</a> when creating this
                project page.</p> -->
            <!-- <p> This project is licensed under <a
                href="https://github.com/ykdai/BracketFlare/blob/main/LICENSE">NTU S-Lab License 1.0</a>. Redistribution and use should follow this license.</p> -->
        </section>

    </div>


</body>

</html>
